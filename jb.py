import requests
import json
import re
import urllib.parse
from time import gmtime, strftime
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import openai
from requests.auth import HTTPBasicAuth
from config import *

openai.api_key = OPENAI_API_KEY
CATEGORY_NAME = "ì‹¤ì‹œê°„ì •ë³´ | ì§€ê¸ˆ í™•ì¸í•´ì•¼ í•  ìµœì‹  ë‰´ìŠ¤ì™€ í•«ì´ìŠˆ"

# êµ¬ê¸€ íŠ¸ë Œë“œ í‚¤ì›Œë“œ 1ê°œ ê°€ì ¸ì˜¤ê¸° (Selenium)
def get_google_trends_keywords():
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    driver = webdriver.Chrome(options=options)
    driver.get("https://trends.google.co.kr/trending?geo=KR&hours=4")
    driver.implicitly_wait(5)

    try:
        keyword_element = driver.find_element(By.CSS_SELECTOR, 'div.mZ3RIc')
        keyword = keyword_element.text.strip()
    except Exception as e:
        keyword = None
        print("âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨:", e)

    driver.quit()
    return [keyword]

# êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
def search_news_snippets(keyword, max_results=3):
    url = f"https://www.google.com/search?q={urllib.parse.quote(keyword)}&hl=ko"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')

    results = []
    for elem in soup.select('div.BNeawe.s3v9rd.AP7Wnd'):
        text = elem.get_text(strip=True)
        if text and len(text) > 40:
            results.append(f"- {text}")
        if len(results) >= max_results:
            break
    return "\n".join(results)

# GPTì—ê²Œ ê¸€ ìƒì„± ìš”ì²­
def generate_blog_post(keyword):
    info_snippets = search_news_snippets(keyword)

    prompt = f"""
í‚¤ì›Œë“œ: "{keyword}"

ì•„ë˜ëŠ” ì´ í‚¤ì›Œë“œì— ëŒ€í•œ ê²€ìƒ‰ ì •ë³´ ìš”ì•½ì…ë‹ˆë‹¤:
\"\"\"
{info_snippets}
\"\"\"

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
- í•´ë‹¹ í‚¤ì›Œë“œì— ëŒ€í•´ ì‚¬ëŒë“¤ì´ ê¶ê¸ˆí•´í•  ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬
- ë°°ê²½ ì„¤ëª…, ê´€ë ¨ ì´ìŠˆ, ëŒ€ì¤‘ì˜ ë°˜ì‘, ì£¼ëª©í•  ì  ë“±ì„ í¬í•¨í•´ë„ ì¢‹ìŒ
- SEO ìµœì í™”
- 3000ì ì´ìƒ
- í‚¤ì›Œë“œë¥¼ ì œëª©ê³¼ ì„œë¡ ì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
- ë„ˆë¬´ ë”±ë”±í•œ ì„¤ëª… ë§ê³ , ë¸”ë¡œê·¸ ê¸€ì²˜ëŸ¼ ì¹œê·¼í•˜ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ì²´ë¡œ ì‘ì„±
"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ëŠ” ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )

    print("âœ… GPT ê¸€ ìƒì„± ì™„ë£Œ")
    return response['choices'][0]['message']['content']



# HTML í¬ë§· (ë³¸ë¬¸ì— ì´ë¯¸ì§€ ì‚½ì…)
def format_html_with_images(text, image_urls):
    html = []
    lines = text.strip().split('\n')
    img_index = 0

    for line in lines:
        line = line.strip()
        if not line:
            continue
        if re.match(r'^\d+\.\s', line):
            html.append(f"<h2>{line}</h2>")
        else:
            html.append(f"<p>{line}</p>")
            if img_index < len(image_urls):
                html.append(f'<img src="{image_urls[img_index]}" style="width:100%; margin:20px 0; border-radius:10px;">')
                img_index += 1
    return '\n'.join(html)

# êµ¬ê¸€ ì´ë¯¸ì§€ ê²€ìƒ‰
def search_google_images(keyword, max_results=4):
    search_url = f"https://www.google.com/search?q={urllib.parse.quote(keyword)}&tbm=isch"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(search_url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')

    image_urls = []
    for img_tag in soup.select('img'):
        src = img_tag.get('src')
        if src and src.startswith('http'):
            image_urls.append(src)
        if len(image_urls) >= max_results:
            break
    return image_urls

# ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ í›„ iframe ì‚½ì… (ë§¨ í•˜ë‹¨ì—ë§Œ ì‚½ì…)
def get_youtube_embed_html(keyword):
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    import time
    import urllib.parse

    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--window-size=1920x1080')

    driver = webdriver.Chrome(options=options)
    search_url = f"https://www.youtube.com/results?search_query={urllib.parse.quote(keyword)}"
    driver.get(search_url)
    time.sleep(3)

    video_id = ""
    try:
        video_links = driver.find_elements(By.CSS_SELECTOR, 'a#video-title')

        for video in video_links:
            href = video.get_attribute("href")
            if href and "watch?v=" in href:
                video_id = href.split("watch?v=")[-1].split("&")[0]  # ì˜ìƒ IDë§Œ ì¶”ì¶œ
                print("ğŸ¥ ìœ íŠœë¸Œ ì˜ìƒ ID:", video_id)
                break

    except Exception as e:
        print("âŒ ìœ íŠœë¸Œ ì˜ìƒ ì¶”ì¶œ ì‹¤íŒ¨:", e)

    driver.quit()

    if video_id:
        return f"""
<div style="margin:20px 0;">
<iframe width="100%" height="315" src="https://www.youtube.com/embed/{video_id}" frameborder="0" allowfullscreen></iframe>
</div>
"""
    else:
        print("âš ï¸ ìœ íŠœë¸Œ ì˜ìƒ IDë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.")
        return ""


# Yoastìš© SEO ë©”íƒ€ ë° ë‚´ìš© ìµœì¢… ì¡°ë¦½
def insert_seo_meta(html, keyword, meta_desc):
    return f"""<meta name=\"description\" content=\"{meta_desc}\">
<meta name=\"keywords\" content=\"{keyword}\">\n\n{html}"""

# í¬ìŠ¤íŠ¸ ë³¸ë¬¸ ë§ˆë¬´ë¦¬
def build_html(keyword, content, youtube_html):
    return f"""
<h2>{keyword} - ì‹¤ì‹œê°„ ì´ìŠˆ ë¶„ì„</h2>
<p><strong>ì´ìŠˆ ìš”ì•½:</strong> ì§€ê¸ˆ í•œêµ­ì—ì„œ ê°€ì¥ ì£¼ëª©ë°›ê³  ìˆëŠ” í‚¤ì›Œë“œ <strong>{keyword}</strong>ì— ëŒ€í•´ ê¹Šì´ ìˆê²Œ ë‹¤ë¤„ë´…ë‹ˆë‹¤.</p>
<h3>ğŸ“Œ ìƒì„¸ ë¶„ì„</h3>
{content}
{youtube_html}
"""

# ìŠ¬ëŸ¬ê·¸ ìˆœì°¨ ì¦ê°€ìš© ì¸ë±ìŠ¤ í™•ì¸
def get_next_slug_index():
    prefix = "jb"
    page = 1
    all_slugs = []
    while True:
        res = requests.get(f"{WP_URL}?per_page=100&page={page}", auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
        if res.status_code != 200:
            break
        data = res.json()
        if not data:
            break
        matching = [post.get("slug", "") for post in data if post.get("slug", "").startswith(prefix + "-")]
        all_slugs.extend(matching)
        page += 1
    max_index = 0
    for slug in all_slugs:
        match = re.match(r"jb-(\d+)$", slug)
        if match:
            idx = int(match.group(1))
            max_index = max(max_index, idx)
    return max_index + 1

# ì¹´í…Œê³ ë¦¬ ë° íƒœê·¸ ì²˜ë¦¬
def get_or_create_category(name):
    url = WP_URL.replace("/posts", "/categories")
    res = requests.get(f"{url}?search={name}", auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
    if res.json(): return res.json()[0]['id']
    res = requests.post(url, headers={"Content-Type": "application/json"}, data=json.dumps({"name": name}), auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
    return res.json()['id']

def get_or_create_tag(name):
    url = WP_URL.replace("/posts", "/tags")
    res = requests.get(f"{url}?search={name}", auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
    if res.json(): return res.json()[0]['id']
    res = requests.post(url, headers={"Content-Type": "application/json"}, data=json.dumps({"name": name}), auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
    return res.json()['id']

# ì›Œë“œí”„ë ˆìŠ¤ ì—…ë¡œë“œ
def post_to_wp(title, content, keyword, meta_desc):
    slug = f"jb-{get_next_slug_index()}"
    category_id = get_or_create_category(CATEGORY_NAME)
    tag_id = get_or_create_tag(keyword.split()[0])

    post = {
        "title": f"{title}",
        "slug": slug,
        "content": content,
        "status": "publish",
        "tags": [tag_id],
        "categories": [category_id],
        "meta": {
            "_yoast_wpseo_focuskw": keyword,
            "_yoast_wpseo_metadesc": meta_desc
        }
    }

    res = requests.post(WP_URL, headers={"Content-Type": "application/json"}, data=json.dumps(post), auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
    if res.status_code in [200, 201]:
        print(f"âœ… ì—…ë¡œë“œ ì„±ê³µ - {title}")
    else:
        print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {res.status_code}", res.text)

# ì‹¤í–‰
if __name__ == "__main__":
    try:
        keywords = get_google_trends_keywords()
        for keyword in keywords:
            print(f"ğŸš€ í‚¤ì›Œë“œ: {keyword}")
            text = generate_blog_post(keyword)
            image_urls = search_google_images(keyword)
            html_content = format_html_with_images(text, image_urls)
            youtube = get_youtube_embed_html(keyword)
            full_body = build_html(keyword, html_content, youtube)
            meta_desc = text.strip().split('\n')[0][:155]
            full_with_meta = insert_seo_meta(full_body, keyword, meta_desc)
            post_to_wp(keyword, full_with_meta, keyword, meta_desc)
    except Exception as e:
        import traceback
        print("âŒ ì˜¤ë¥˜ ë°œìƒ:", e)
        traceback.print_exc()
    input("\nì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. Enter í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì°½ì´ ë‹«í™ë‹ˆë‹¤.")