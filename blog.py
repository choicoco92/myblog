# âœ… í†µí•©ëœ ìë™ í¬ìŠ¤íŒ… ìŠ¤í¬ë¦½íŠ¸: íŠ¸ë Œë“œ ë‰´ìŠ¤ + ì¿ íŒ¡ ìƒí’ˆ ì‚½ì… (og:image ì ìš© í¬í•¨ ì „ì²´ì½”ë“œ)

import requests, json, openai, hashlib, hmac, re, time, random
from requests.auth import HTTPBasicAuth
from bs4 import BeautifulSoup
from config import *
from bs4 import BeautifulSoup
import requests
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from urllib.parse import quote
from urllib.parse import urlparse, unquote
from datetime import datetime
import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
WP_URL = os.getenv('WP_URL')
WP_USERNAME = os.getenv('WP_USERNAME')
WP_PASSWORD = os.getenv('WP_PASSWORD')
PEXELS_API_KEY = os.getenv('PEXELS_API_KEY')
CP_ACCESS_KEY = os.getenv('CP_ACCESS_KEY')
CP_SECRET_KEY = os.getenv('CP_SECRET_KEY')

print("ğŸ”‘ OPENAI_API_KEY:", OPENAI_API_KEY[:10] + "...")
print("ğŸŒ WP_URL:", WP_URL)

openai.api_key = OPENAI_API_KEY

CATEGORY_MAP = {
    "today-trend": "ğŸŒ ì˜¤ëŠ˜ì˜ íŠ¸ë Œë“œ",
    "ai-tech": "ğŸ¤– AI & ê¸°ìˆ ",
    "life-hacks": "ğŸ§  ìƒí™œì •ë³´",
    "finance": "ğŸ’° ê¸ˆìœµ/ì¬í…Œí¬",
    "health": "ğŸ’ª ê±´ê°•/ì›°ë¹™",
    "tech": "ğŸ”Œ í…Œí¬/ê°€ì ¯",
    "life": "ğŸ  ë¼ì´í”„ìŠ¤íƒ€ì¼",
    "ai_generated": "ğŸ¯ AI ì¶”ì²œ"
}

COUPANG_CATEGORY_SLUG_MAP = {
    1001: "hot-now", 1002: "hot-now", 1010: "hot-now", 1011: "kids-life",
    1013: "home-living", 1014: "daily-pick", 1015: "home-living", 1016: "tech-gadgets",
    1017: "travel-leisure", 1018: "daily-pick", 1019: "daily-pick", 1020: "daily-pick",
    1021: "daily-pick", 1024: "daily-pick", 1025: "travel-leisure", 1026: "travel-leisure",
    1029: "pet-picks", 1030: "kids-life"
}

HIGH_CPC_KEYWORDS = {
    "finance": ["ëŒ€ì¶œ", "ì‹ ìš©ì¹´ë“œ", "ë³´í—˜", "ì£¼ì‹ íˆ¬ì", "ë¶€ë™ì‚°"],
    "health": ["ë‹¤ì´ì–´íŠ¸ ë³´ì¡°ì œ", "ì˜ì–‘ì œ ì¶”ì²œ", "íƒˆëª¨ ì¹˜ë£Œ", "ê±´ê°• ê²€ì§„"],
    "tech": ["ë…¸íŠ¸ë¶ ì¶”ì²œ", "ê²Œì´ë° ë§ˆìš°ìŠ¤", "í´ë¼ìš°ë“œ í˜¸ìŠ¤íŒ…", "AI ì„œë¹„ìŠ¤"],
    "life": ["ì´ì‚¬ ì¤€ë¹„", "ì…€í”„ ì¸í…Œë¦¬ì–´", "ê²°í˜¼ ì¤€ë¹„", "ìë™ì°¨ ë³´í—˜"]
}

def generateHmac(method, full_url_path, secretKey, accessKey):
    from time import gmtime, strftime
    signed_date = strftime('%y%m%dT%H%M%SZ', gmtime())
    path, query = full_url_path.split('?', 1) if '?' in full_url_path else (full_url_path, "")
    message = signed_date + method + path + query
    signature = hmac.new(secretKey.encode(), message.encode(), hashlib.sha256).hexdigest()
    return f"CEA algorithm=HmacSHA256, access-key={accessKey}, signed-date={signed_date}, signature={signature}"

def get_random_best_product():
    for _ in range(5):
        category_id = random.choice(list(COUPANG_CATEGORY_SLUG_MAP.keys()))
        path = f"/v2/providers/affiliate_open_api/apis/openapi/products/bestcategories/{category_id}?limit=30"
        url = f"https://api-gateway.coupang.com{path}"
        auth_header = generateHmac("GET", path, CP_SECRET_KEY, CP_ACCESS_KEY)
        r = requests.get(url, headers={"Authorization": auth_header})
        if r.status_code == 200 and r.json().get("data"):
            p = random.choice(r.json()["data"])
            return {
                "name": p["productName"],
                "image": p["productImage"],
                "url": p["productUrl"]
            }
    return None

def get_news_title_from_url(news_url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(news_url, headers=headers, timeout=5)
        soup = BeautifulSoup(resp.text, "html.parser")
        title_tag = soup.find("meta", property="og:title")
        if title_tag:
            return title_tag["content"].strip()
        return soup.title.string.strip() if soup.title else None
    except Exception as e:
        print(f"âš ï¸ ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None


def extract_og_image(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=5)
        if resp.status_code != 200:
            return None
        soup = BeautifulSoup(resp.text, 'html.parser')
        og_tag = soup.find("meta", property="og:image")
        if og_tag and og_tag.get("content"):
            return og_tag["content"]
    except Exception as e:
        print("âš ï¸ og:image ì¶”ì¶œ ì‹¤íŒ¨:", e)
    return None

def map_keyword_to_category(keyword):
    keyword = keyword.lower()
    if any(k in keyword for k in ["ai", "chatgpt", "gpt", "suno"]):
        return "ai-tech"
    elif any(k in keyword for k in ["ë‹¤ì´ì–´íŠ¸", "ìƒí™œ", "ì •ë¦¬", "ì ˆì•½"]):
        return "life-hacks"
    elif any(k in keyword for k in ["ìœ íŠœë¸Œ", "youtube", "ì˜ìƒ", "ì‡¼ì¸ "]):
        return "today-video"
    elif any(k in keyword for k in ["ë‰´ìŠ¤", "ì†ë³´", "í—¤ë“œë¼ì¸"]):
        return "briefing"
    elif any(k in keyword for k in ["ê²°ì‚°", "ìš”ì•½", "í†µê³„", "í†±10"]):
        return "archive"
    else:
        return "today-trend"

def get_trending_with_news(count=3):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.get("https://trends.google.co.kr/trends/trendingsearches/daily?geo=KR")
    time.sleep(3)

    elements = driver.find_elements(By.XPATH, '//tr[@role="row"]/td[2]/div[1]')
    keywords = [el.text.strip() for el in elements if el.text.strip()]
    driver.quit()

    selected = keywords[:count]
    results = []

    for keyword in selected:
        print(f"ğŸ” í‚¤ì›Œë“œ: {keyword}")
        news_url, image_url, news_title = get_news_url_and_og_image(keyword)
        category = map_keyword_to_category(keyword)

        if not news_url:
            continue

        news_titles = [news_title] if news_title else [keyword]
        results.append((keyword, news_titles, category, image_url))

    return results

def get_news_url_and_og_image(keyword):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("window-size=1920x1080")
    options.add_argument("user-agent=Mozilla/5.0")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    try:
        query = quote(keyword)
        url = f"https://search.naver.com/search.naver?query={query}"
        driver.get(url)

        wait = WebDriverWait(driver, 5)
        links = driver.find_elements(By.CSS_SELECTOR, "a[href*='n.news.naver.com']")
        news_url = None
        for link in links:
            href = link.get_attribute("href")
            if href:
                news_url = href
                break

        if not news_url:
            print(f"âŒ [{keyword}] ë‰´ìŠ¤ ë§í¬ ì—†ìŒ")
            return None, None, None

        image_url = extract_og_image(news_url)
        news_title = get_news_title_from_url(news_url)
        return news_url, image_url, news_title

    except Exception as e:
        print(f"âš ï¸ [{keyword}] ë‰´ìŠ¤ URL/ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None, None, None
    finally:
        driver.quit()


# ë¸”ë¡œê·¸ ê¸€ ìƒì„±

def generate_meta_description(title):
    current_year = datetime.now().year
    return f"{title}ì— ëŒ€í•œ {current_year}ë…„ ìµœì‹  ì •ë³´ì™€ ì „ë¬¸ê°€ ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”. ìƒì„¸í•œ ë¹„êµ ë¶„ì„, êµ¬ë§¤ ê°€ì´ë“œ, ì¶”ì²œ ìˆœìœ„ê¹Œì§€ í•œ ë²ˆì— ì•Œì•„ë³´ì„¸ìš”."

def generate_blog_content(keyword, news_titles, category):
    current_year = datetime.now().year
    joined_titles = "\n".join([f"- {t}" for t in news_titles])
    prompt = f"""
ğŸ“° '{keyword}'ì— ëŒ€í•œ ìƒì„¸í•˜ê³  í¬ê´„ì ì¸ êµ¬ë§¤/ì´ìš© ê°€ì´ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë‰´ìŠ¤ ì œëª©: {joined_titles}
ì¹´í…Œê³ ë¦¬: {category}

ë…ìê°€ ì‹¤ì œë¡œ í–‰ë™í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
"""
    messages = [
        {
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ ìƒì„¸í•˜ê³  í¬ê´„ì ì¸ êµ¬ë§¤/ì´ìš© ê°€ì´ë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ í•œêµ­ì–´ë¡œ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
                "1. **ë¶„ëŸ‰**: ìµœì†Œ 2000ì ì´ìƒ, 3000-4000ì ê¶Œì¥ìœ¼ë¡œ ë§¤ìš° ìƒì„¸í•˜ê³  í¬ê´„ì ì¸ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤.\n"
                "2. **êµ¬ì²´ì„±**: ì¶”ìƒì ì¸ ì„¤ëª… ëŒ€ì‹  êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ê°€ê²©, ë°©ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.\n"
                "3. **ì‹¤ì œ ì •ë³´**: ê°€ìƒì˜ XX, YY ëŒ€ì‹  ì‹¤ì œ ë¸Œëœë“œëª…, ì œí’ˆëª…, ì„œë¹„ìŠ¤ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
                "4. **êµ¬ì²´ì  í˜œíƒ**: ì‹¤ì œ í˜œíƒê³¼ ì¡°ê±´ì„ ì •í™•íˆ ì œì‹œí•©ë‹ˆë‹¤ (ì˜ˆ: 'ì—°íšŒë¹„ 3ë§Œì›', 'í• ì¸ìœ¨ 20%', 'ë¬´ë£Œ ë°°ì†¡').\n"
                f"5. **ìµœì‹  ì •ë³´**: {current_year}ë…„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  ì œí’ˆ, ì„œë¹„ìŠ¤, ê°€ê²© ì •ë³´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 2021ë…„, 2022ë…„ ë“± ì˜¤ë˜ëœ ì •ë³´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
                f"   - ìŠ¤ë§ˆíŠ¸í°: iPhone 16 Pro Max, Galaxy S25 Ultra, Pixel 9 Pro ë“± {current_year}ë…„ ìµœì‹  ëª¨ë¸ ì‚¬ìš©\n"
                f"   - ë…¸íŠ¸ë¶: MacBook Pro M4, Galaxy Book5 Ultra, Dell XPS 16 ë“± {current_year}ë…„ ìµœì‹  ëª¨ë¸ ì‚¬ìš©\n"
                f"   - ì‹ ìš©ì¹´ë“œ: {current_year}ë…„ ìµœì‹  í˜œíƒê³¼ ì¡°ê±´ ì‚¬ìš©\n"
                f"   - ë³´í—˜: {current_year}ë…„ ìµœì‹  ìƒí’ˆê³¼ ë³´ì¥ ë‚´ìš© ì‚¬ìš©\n"
                "6. **í‚¤ì›Œë“œ ì¤‘ì‹¬ ì†Œì œëª©**: í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ì†Œì œëª©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì˜ˆì‹œ:\n"
                f"   - í‚¤ì›Œë“œê°€ 'ë…¸íŠ¸ë¶ ì¶”ì²œ'ì¸ ê²½ìš°: '{current_year}ë…„ ìµœê³ ì˜ ë…¸íŠ¸ë¶ ì¶”ì²œ TOP 7', 'ìš©ë„ë³„ ë…¸íŠ¸ë¶ ì¶”ì²œ ê°€ì´ë“œ', 'ê°€ê²©ëŒ€ë³„ ë…¸íŠ¸ë¶ ì¶”ì²œ', 'ë…¸íŠ¸ë¶ êµ¬ë§¤ ì‹œ ì²´í¬í¬ì¸íŠ¸', 'ì‹¤ì œ ì‚¬ìš©ì í›„ê¸°', 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸', 'ë§ˆë¬´ë¦¬' ë“±\n"
                f"   - í‚¤ì›Œë“œê°€ 'ì‹ ìš©ì¹´ë“œ ì¶”ì²œ'ì¸ ê²½ìš°: '{current_year}ë…„ ìµœê³ ì˜ ì‹ ìš©ì¹´ë“œ ì¶”ì²œ TOP 5', 'ì—°ë´‰ë³„ ì‹ ìš©ì¹´ë“œ ì¶”ì²œ', 'í˜œíƒë³„ ì‹ ìš©ì¹´ë“œ ì¶”ì²œ', 'ì‹ ìš©ì¹´ë“œ ì‹ ì²­ ì‹œ ì£¼ì˜ì‚¬í•­', 'ì‹¤ì œ í˜œíƒ ë¹„êµ', 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸', 'ë§ˆë¬´ë¦¬' ë“±\n"
                f"   - í‚¤ì›Œë“œê°€ 'ë³´í—˜ ì¶”ì²œ'ì¸ ê²½ìš°: '{current_year}ë…„ ìµœê³ ì˜ ë³´í—˜ ì¶”ì²œ TOP 6', 'ë‚˜ì´ë³„ ë³´í—˜ ì¶”ì²œ', 'ìƒí’ˆë³„ ë³´í—˜ ì¶”ì²œ', 'ë³´í—˜ ê°€ì… ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸', 'ì‹¤ì œ ë³´ì¥ ë¹„êµ', 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸', 'ë§ˆë¬´ë¦¬' ë“±\n"
                "7. **ìƒì„¸í•œ êµ¬ì¡°**: í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ìì—°ìŠ¤ëŸ¬ìš´ ì†Œì œëª©ë“¤ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤. ì˜ˆì‹œ:\n"
                f"   - í‚¤ì›Œë“œê°€ 'ë…¸íŠ¸ë¶ ì¶”ì²œ'ì¸ ê²½ìš°: '{current_year}ë…„ ìµœê³ ì˜ ë…¸íŠ¸ë¶ ì¶”ì²œ TOP 7', 'ìš©ë„ë³„ ë…¸íŠ¸ë¶ ì¶”ì²œ ê°€ì´ë“œ', 'ê°€ê²©ëŒ€ë³„ ë…¸íŠ¸ë¶ ì¶”ì²œ', 'ë…¸íŠ¸ë¶ êµ¬ë§¤ ì‹œ ì²´í¬í¬ì¸íŠ¸', 'ì‹¤ì œ ì‚¬ìš©ì í›„ê¸°', 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸', 'ë§ˆë¬´ë¦¬' ë“±\n"
                f"   - í‚¤ì›Œë“œê°€ 'ì‹ ìš©ì¹´ë“œ ì¶”ì²œ'ì¸ ê²½ìš°: '{current_year}ë…„ ìµœê³ ì˜ ì‹ ìš©ì¹´ë“œ ì¶”ì²œ TOP 5', 'ì—°ë´‰ë³„ ì‹ ìš©ì¹´ë“œ ì¶”ì²œ', 'í˜œíƒë³„ ì‹ ìš©ì¹´ë“œ ì¶”ì²œ', 'ì‹ ìš©ì¹´ë“œ ì‹ ì²­ ì‹œ ì£¼ì˜ì‚¬í•­', 'ì‹¤ì œ í˜œíƒ ë¹„êµ', 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸', 'ë§ˆë¬´ë¦¬' ë“±\n"
                f"   - í‚¤ì›Œë“œê°€ 'ë³´í—˜ ì¶”ì²œ'ì¸ ê²½ìš°: '{current_year}ë…„ ìµœê³ ì˜ ë³´í—˜ ì¶”ì²œ TOP 6', 'ë‚˜ì´ë³„ ë³´í—˜ ì¶”ì²œ', 'ìƒí’ˆë³„ ë³´í—˜ ì¶”ì²œ', 'ë³´í—˜ ê°€ì… ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸', 'ì‹¤ì œ ë³´ì¥ ë¹„êµ', 'ìì£¼ ë¬»ëŠ” ì§ˆë¬¸', 'ë§ˆë¬´ë¦¬' ë“±\n"
                "8. **ì‹¤ìš©ì„±**: ë…ìê°€ ë°”ë¡œ ë”°ë¼í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë‹¨ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n"
                "9. **ì‹ ë¢°ì„±**: ì‹¤ì œ ê²€ì¦ ê°€ëŠ¥í•œ ì •ë³´ì™€ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n"
                "10. **ë¹„êµ ì •ë³´**: ìµœì†Œ 5-7ê°œì˜ êµ¬ì²´ì ì¸ ì˜µì…˜ì„ ì‹¤ì œ ì •ë³´ë¡œ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.\n"
                "11. **ê°€ê²© ì •ë³´**: ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ê°€ê²© ë²”ìœ„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.\n"
                "12. **ì£¼ì˜ì‚¬í•­**: ì‹¤ì œ ì´ìš© ì‹œ ì£¼ì˜í•´ì•¼ í•  ì ë“¤ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•©ë‹ˆë‹¤.\n"
                "13. **FAQ ì„¹ì…˜**: í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í¬í•¨í•©ë‹ˆë‹¤.\n"
                "14. **í–‰ë™ ìœ ë„**: ê¸€ ë§ˆì§€ë§‰ì— ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ í–‰ë™ ë‹¨ê³„ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.\n"
                "15. **í‚¤ì›Œë“œ ë°€ë„**: í•µì‹¬ í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ 8-10íšŒ ì‚¬ìš©í•˜ë˜, ê³¼ë„í•œ ë°˜ë³µì„ í”¼í•©ë‹ˆë‹¤.\n"
                "16. **ê¸´ê¸‰ì„±**: 'ì§€ê¸ˆ', 'ë°”ë¡œ', 'ì„œë‘˜ëŸ¬' ë“± ê¸´ê¸‰ì„±ì„ ê°•ì¡°í•˜ëŠ” í‘œí˜„ì„ ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
                "17. **HTML íƒœê·¸**: <h2>, <h3>, <h4>, <p>, <ul>, <li>, <strong>, <em> íƒœê·¸ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.\n"
                "18. **ì´ëª¨ì§€**: ê° ì„¹ì…˜ì— ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.\n"
                "19. **ì‹¤ì œ ë§í¬**: ê°€ëŠ¥í•œ ê²½ìš° ì‹¤ì œ ì‹ ì²­ ë§í¬ë‚˜ ê³µì‹ í™ˆí˜ì´ì§€ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n"
                "20. **ìƒì„¸í•œ ì„¤ëª…**: ê° ì„¹ì…˜ì—ì„œ ì¶©ë¶„íˆ ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.\n"
                "21. **í‚¤ì›Œë“œ ì—°ê´€ì„±**: ëª¨ë“  ì†Œì œëª©ê³¼ ë‚´ìš©ì´ í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ë˜ë„ë¡ ì‘ì„±í•©ë‹ˆë‹¤.\n"
                "22. **SEO ìµœì í™”**: ì œëª© íƒœê·¸(H1)ëŠ” í•œ ë²ˆë§Œ ì‚¬ìš©í•˜ê³ , í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n"
                "23. **ë‚´ë¶€ ë§í¬**: ê´€ë ¨ í‚¤ì›Œë“œë‚˜ ê°œë…ì— ëŒ€í•œ ë‚´ë¶€ ë§í¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n"
                "24. **ì™¸ë¶€ ë§í¬**: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì™¸ë¶€ ì†ŒìŠ¤ì— ëŒ€í•œ ë§í¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n"
                "25. **ì´ë¯¸ì§€ ìµœì í™”**: ì´ë¯¸ì§€ì— ì ì ˆí•œ alt íƒœê·¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n"
                "26. **ë§ˆë¬´ë¦¬ ë§í¬**: ê¸€ ë§ˆì§€ë§‰ì— ì–¸ê¸‰ëœ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ì˜ ì‹¤ì œ ë§í¬ë¥¼ HTML <a> íƒœê·¸ë¡œ í¬í•¨í•©ë‹ˆë‹¤. ì˜ˆì‹œ: <a href='https://www.apple.com/kr/' target='_blank'>ì•„ì´í° 16 Pro Max</a>"
            )
        },
        {"role": "user", "content": prompt}
    ]

    res = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7,
        max_tokens=4000
    )
    return res['choices'][0]['message']['content']



def extract_tags_from_text(keyword, news_titles):
    base = " ".join(news_titles) + " " + keyword
    words = re.findall(r'[ê°€-í£a-zA-Z]{2,20}', base)
    return list(set(words))[:5]


def get_or_create_category(slug):
    name = CATEGORY_MAP.get(slug, slug.replace('-', ' ').title())
    url = f"{WP_URL.replace('/posts', '/categories')}"
    r = requests.get(f"{url}?slug={slug}", auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
    if r.status_code == 200 and r.json():
        return r.json()[0]['id']
    
    res = requests.post(
        url,
        headers={"Content-Type": "application/json"},
        data=json.dumps({"name": name, "slug": slug}),
        auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
    )
    if res.status_code == 201:
        return res.json().get('id')
    print(f"âš ï¸ ì¹´í…Œê³ ë¦¬ ìƒì„±/ì¡°íšŒ ì‹¤íŒ¨: {res.text}")
    return None


def get_or_create_tags(tag_names):
    tag_ids = []
    url = f"{WP_URL.replace('/posts', '/tags')}"
    for tag in tag_names:
        r = requests.get(f"{url}?search={tag}", auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
        if r.status_code == 200 and r.json():
            tag_ids.append(r.json()[0]['id'])
        else:
            res = requests.post(
                url,
                headers={"Content-Type": "application/json"},
                data=json.dumps({"name": tag}),
                auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
            )
            if res.status_code == 201:
                tag_ids.append(res.json().get("id"))
    return tag_ids


def reword_title(keyword):
    current_year = datetime.now().year
    patterns = [
        f"{current_year}ë…„ {keyword} ì™„ë²½ ê°€ì´ë“œ",
        f"{keyword} ì„ íƒí•˜ëŠ” ë°©ë²• ì´ì •ë¦¬",
        f"{keyword} ë¹„êµ ë¶„ì„ ë° ì¶”ì²œ",
        f"{keyword} ì•Œì•„ë³´ê¸° - ì „ë¬¸ê°€ ì¡°ì–¸",
        f"{keyword} êµ¬ë§¤ ì „ í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸",
        f"{keyword} ìµœì‹  ì •ë³´ì™€ ì¶”ì²œ ìˆœìœ„",
        f"{keyword} ì™„ì „ ë¶„ì„ - ì´ë ‡ê²Œ ì„ íƒí•˜ì„¸ìš”",
        f"{keyword} ê°€ì´ë“œ - ì‹¤ì „ í™œìš©ë²•",
        f"{keyword} ë¹„êµ ë° êµ¬ë§¤ ê°€ì´ë“œ",
        f"{keyword} ì¶”ì²œ - ì „ë¬¸ê°€ê°€ ì•Œë ¤ì£¼ëŠ” ì„ íƒë²•"
    ]
    return random.choice(patterns)


def upload_image_to_wp(image_url, keyword=None):
    try:
        resp = requests.get(image_url, timeout=10)
        resp.raise_for_status()
        img_data = resp.content
    except Exception as e:
        print("âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨:", e)
        return None

    parsed_url = urlparse(image_url)
    filename = unquote(parsed_url.path.split("/")[-1])
    ext = filename.split(".")[-1].lower().split("?")[0]
    content_type = {"jpg": "image/jpeg", "jpeg": "image/jpeg", "png": "image/png", "webp": "image/webp"}.get(ext, "image/jpeg")

    # SEO ìµœì í™”ëœ alt íƒœê·¸ ìƒì„±
    alt_text = f"{keyword} ê´€ë ¨ ì´ë¯¸ì§€" if keyword else "ê´€ë ¨ ì´ë¯¸ì§€"

    media_headers = {
        "Content-Disposition": f"attachment; filename=image.{ext}",
        "Content-Type": content_type
    }

    try:
        media_response = requests.post(
            WP_URL.replace("/posts", "/media"),
            headers=media_headers,
            data=img_data,
            auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
        )
        media_response.raise_for_status()
        media_json = media_response.json()
        
        # ì´ë¯¸ì§€ì— alt íƒœê·¸ ì¶”ê°€
        if keyword:
            alt_update = requests.put(
                f"{WP_URL.replace('/posts', '/media')}/{media_json['id']}",
                headers={"Content-Type": "application/json"},
                data=json.dumps({"alt_text": alt_text}),
                auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
            )
        
        print("âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ:", media_json.get("source_url"))
        return media_json["id"]
    except Exception as e:
        print("âŒ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨:", e)
        return None

def generate_tags_with_gpt(keyword, news_titles):
    prompt = f"ë¸”ë¡œê·¸ ê¸€ì˜ í•µì‹¬ í‚¤ì›Œë“œê°€ '{keyword}'ì´ê³  ê´€ë ¨ ë‰´ìŠ¤ëŠ” '{' / '.join(news_titles)}'ì…ë‹ˆë‹¤. ì´ ê¸€ì— ì í•©í•œ íƒœê·¸ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ 10ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”. (ì˜ˆ: íƒœê·¸1, íƒœê·¸2, ...)"
    res = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5
    )
    tags_str = res['choices'][0]['message']['content']
    return [tag.strip() for tag in tags_str.split(",") if tag.strip()]


def post_to_wordpress(title, html, category_slug, image_url):
    cat_id = get_or_create_category(category_slug)
    if not cat_id:
        print("âŒ ì¹´í…Œê³ ë¦¬ IDë¥¼ ì–»ì§€ ëª»í•´ í¬ìŠ¤íŒ…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return

    meta_desc = generate_meta_description(title)
    
    try:
        tag_names = generate_tags_with_gpt(title, [title])
    except Exception as e:
        print("âš ï¸ GPT íƒœê·¸ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´:", e)
        tag_names = re.findall(r'[ê°€-í£a-zA-Z]{2,20}', title)[:5]

    tag_ids = get_or_create_tags(tag_names)
    media_id = None
    if image_url:
        media_id = upload_image_to_wp(image_url, title)
        if media_id:
            html = f'<img src="{image_url}" alt="{title}" style="max-width:100%; height:auto; border-radius:10px; margin-bottom: 20px;" />' + html

    # ì†ë„ ìµœì í™” ë©”íƒ€ íƒœê·¸ ì¶”ê°€
    html = add_speed_optimization_meta(html, title)

    # ì—°ê´€ ì¿ íŒ¡ ìƒí’ˆ ì¶”ê°€
    product = search_coupang_products(title)
    if product and product.get('url'):
        product_html = f"""
        <div style="text-align: center; margin: 30px 0; padding: 20px; border: 1px solid #ddd; border-radius: 10px;">
            <a href="{product['url']}" target="_blank" rel="noopener sponsored">
                <img src="{product['image']}" alt="{product['name']}" style="width: 200px; height: 200px; object-fit: cover; border-radius: 8px; margin-bottom: 15px;">
            </a>
            <h4 style="margin: 10px 0; font-size: 1.2em;">{product['name']}</h4>
            <a href="{product['url']}" target="_blank" rel="noopener sponsored" style="display: inline-block; background: #ff6b6b; color: white; padding: 10px 20px; border-radius: 5px; text-decoration: none; font-weight: bold;">
                ë°”ë¡œê°€ê¸°
            </a>
        </div>
        """
        html += product_html

    post = {
        "title": reword_title(title),
        "content": html,
        "status": "publish",
        "categories": [cat_id],
        "tags": tag_ids,
        "meta": { 
            "rank_math_focus_keyword": title, 
            "rank_math_description": meta_desc,
            "rank_math_title": reword_title(title),
            "rank_math_robots": "index,follow",
            "rank_math_facebook_title": reword_title(title),
            "rank_math_facebook_description": meta_desc,
            "rank_math_twitter_title": reword_title(title),
            "rank_math_twitter_description": meta_desc,
            "rank_math_twitter_card_type": "summary_large_image",
            "rank_math_schema_type": "Article",
            "rank_math_schema_article_type": "BlogPosting"
        },
        **({"featured_media": media_id} if media_id else {})
    }

    r = requests.post(
        WP_URL,
        headers={"Content-Type": "application/json"},
        data=json.dumps(post),
        auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
    )

    if r.status_code in [200, 201]:
        post_url = r.json().get('link')
        print("âœ… ê¸€ ë“±ë¡ ì™„ë£Œ:", post_url)
        
        # Rank Math SEO ì ìˆ˜ ì¬ê³„ì‚°
        time.sleep(2)
        trigger_seo_recalc(r.json().get('id'))
        
    else:
        print("âŒ ë“±ë¡ ì‹¤íŒ¨:", r.text)

def trigger_seo_recalc(post_id):
    try:
        refresh_res = requests.put(
            f"{WP_URL}/{post_id}",
            headers={"Content-Type": "application/json"},
            data=json.dumps({"status": "publish"}),
            auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
        )
        if refresh_res.status_code == 200:
            print("âœ… Rank Math SEO ì ìˆ˜ ì¬ê³„ì‚° íŠ¸ë¦¬ê±° ì™„ë£Œ")
        else:
            print("âš ï¸ Rank Math ì ìˆ˜ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:", refresh_res.status_code, refresh_res.text)
    except Exception as e:
        print("âŒ Rank Math íŠ¸ë¦¬ê±° ì¤‘ ì˜¤ë¥˜:", e)

def search_coupang_products(keyword, limit=5):
    """í‚¤ì›Œë“œë¡œ ì¿ íŒ¡ ìƒí’ˆì„ ê²€ìƒ‰í•˜ê³  ëœë¤ìœ¼ë¡œ í•˜ë‚˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # ì¿ íŒ¡ì—ì„œ ìƒí’ˆì„ ì°¾ê¸° ì–´ë ¤ìš´ í‚¤ì›Œë“œë“¤ (ëœë¤ ìƒí’ˆ ì¶”ì²œ)
    random_product_keywords = [
        "ë³´í—˜", "ì‹ ìš©ì¹´ë“œ", "ëŒ€ì¶œ", "ê±´ê°•ê²€ì§„", "ê²€ì§„", "ì˜ë£Œ", "ë³´í—˜ë£Œ", "ì¹´ë“œ", "ëŒ€ì¶œìƒí’ˆ", "ê¸ˆìœµìƒí’ˆ"
    ]
    
    # í‚¤ì›Œë“œê°€ ëœë¤ ìƒí’ˆ ì¶”ì²œ ëŒ€ìƒì¸ì§€ í™•ì¸
    should_use_random = any(random_keyword in keyword for random_keyword in random_product_keywords)
    
    if should_use_random:
        print(f"ğŸ” ì¿ íŒ¡ ê²€ìƒ‰ í‚¤ì›Œë“œ: '{keyword}' â†’ ëœë¤ ìƒí’ˆ ì¶”ì²œ")
        # ì¸ê¸° ì¹´í…Œê³ ë¦¬ì—ì„œ ëœë¤ ìƒí’ˆ ì„ íƒ
        popular_categories = [1001, 1002, 1010, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1024, 1025, 1026, 1029, 1030]
        category_id = random.choice(popular_categories)
        
        path = f"/v2/providers/affiliate_open_api/apis/openapi/products/bestcategories/{category_id}?limit=30"
        url = f"https://api-gateway.coupang.com{path}"
        auth_header = generateHmac("GET", path, CP_SECRET_KEY, CP_ACCESS_KEY)
        
        try:
            r = requests.get(url, headers={"Authorization": auth_header}, timeout=10)
            r.raise_for_status()
            data = r.json().get("data")
            if data:
                p = random.choice(data)
                return {
                    "name": p.get("productName"),
                    "image": p.get("productImage"),
                    "url": p.get("productUrl")
                }
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ ì¿ íŒ¡ ëœë¤ ìƒí’ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return None
    
    # ì¼ë°˜ ìƒí’ˆ ê²€ìƒ‰
    product_keywords = {
        "ë…¸íŠ¸ë¶": ["ë…¸íŠ¸ë¶", "ë©íƒ‘", "ì»´í“¨í„°"],
        "ìŠ¤ë§ˆíŠ¸í°": ["ìŠ¤ë§ˆíŠ¸í°", "íœ´ëŒ€í°", "í°"],
        "ë‹¤ì´ì–´íŠ¸": ["ë‹¤ì´ì–´íŠ¸", "ê±´ê°•ì‹í’ˆ", "ì˜ì–‘ì œ"],
        "ì˜ì–‘ì œ": ["ì˜ì–‘ì œ", "ê±´ê°•ì‹í’ˆ", "ë¹„íƒ€ë¯¼"],
        "ê²Œì´ë°": ["ê²Œì´ë°", "ê²Œì„", "ê²Œì´ë°ê¸°ê¸°"],
        "ì¸í…Œë¦¬ì–´": ["ì¸í…Œë¦¬ì–´", "ê°€êµ¬", "í™ˆë°ì½”"],
        "ì´ì‚¬": ["ì´ì‚¬", "ì´ì‚¬ìš©í’ˆ", "ë°•ìŠ¤"],
        "ê²°í˜¼": ["ê²°í˜¼", "ì›¨ë”©", "ê²°í˜¼ìš©í’ˆ"]
    }
    
    # í‚¤ì›Œë“œì— ë§ëŠ” ìƒí’ˆ í‚¤ì›Œë“œ ì°¾ê¸°
    search_keyword = keyword
    for key, products in product_keywords.items():
        if key in keyword:
            search_keyword = random.choice(products)
            break
    
    # ê¸°ë³¸ ìƒí’ˆ í‚¤ì›Œë“œ ì¶”ê°€
    if search_keyword == keyword:
        if "ë…¸íŠ¸ë¶" in keyword or "ì»´í“¨í„°" in keyword:
            search_keyword = "ë…¸íŠ¸ë¶"
        elif "ìŠ¤ë§ˆíŠ¸í°" in keyword or "í°" in keyword:
            search_keyword = "ìŠ¤ë§ˆíŠ¸í°"
        elif "ë‹¤ì´ì–´íŠ¸" in keyword or "ê±´ê°•" in keyword:
            search_keyword = "ê±´ê°•ì‹í’ˆ"
        elif "ê²Œì„" in keyword or "ê²Œì´ë°" in keyword:
            search_keyword = "ê²Œì´ë°"
        elif "ì¸í…Œë¦¬ì–´" in keyword or "ê°€êµ¬" in keyword:
            search_keyword = "ê°€êµ¬"
        elif "ì´ì‚¬" in keyword:
            search_keyword = "ì´ì‚¬ìš©í’ˆ"
        elif "ê²°í˜¼" in keyword:
            search_keyword = "ê²°í˜¼ìš©í’ˆ"
    
    path = f"/v2/providers/affiliate_open_api/apis/openapi/products/search?keyword={quote(search_keyword)}&limit={limit}"
    url = f"https://api-gateway.coupang.com{path}"
    auth_header = generateHmac("GET", path, CP_SECRET_KEY, CP_ACCESS_KEY)
    
    print(f"ğŸ” ì¿ íŒ¡ ê²€ìƒ‰ í‚¤ì›Œë“œ: '{keyword}' â†’ '{search_keyword}'")
    
    try:
        r = requests.get(url, headers={"Authorization": auth_header}, timeout=10)
        r.raise_for_status()
        data = r.json().get("data")
        if data and data.get("productData"):
            products = data["productData"]
            if products:
                p = random.choice(products)
                return {
                    "name": p.get("productName"),
                    "image": p.get("productImage"),
                    "url": p.get("productUrl")
                }
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ ì¿ íŒ¡ ìƒí’ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    
    return None

def generate_high_cpc_keywords(category=None, count=5):
    """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ë‹¨ê°€ CPC í‚¤ì›Œë“œë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    if category:
        prompt = f"""
ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ì—ì„œ CPC(í´ë¦­ë‹¹ ë¹„ìš©)ê°€ ë†’ì€ í‚¤ì›Œë“œ {count}ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
ì¹´í…Œê³ ë¦¬: {category}

ì¡°ê±´:
- ê²€ìƒ‰ëŸ‰ì´ ë§ìœ¼ë©´ì„œë„ ìƒì—…ì  ì˜ë„ê°€ ê°•í•œ í‚¤ì›Œë“œ
- "êµ¬ë§¤", "ì˜ˆì•½", "ë°©ë²•", "ì¶”ì²œ", "ë¹„êµ", "ê°€ê²©", "í›„ê¸°", "ìˆœìœ„" ë“± í–‰ë™ ìœ ë„ ë‹¨ì–´ í¬í•¨
- ì‹¤ì œ êµ¬ë§¤ë‚˜ ì„œë¹„ìŠ¤ ì´ìš©ìœ¼ë¡œ ì´ì–´ì§€ëŠ” í‚¤ì›Œë“œ
- í•œêµ­ì–´ë¡œ ì‘ì„±
- ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í‚¤ì›Œë“œë§Œ ë‚˜ì—´ (ì¤„ë°”ê¿ˆ ì—†ì´)

ì˜ˆì‹œ: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, í‚¤ì›Œë“œ4, í‚¤ì›Œë“œ5
"""
    else:
        prompt = f"""
CPC(í´ë¦­ë‹¹ ë¹„ìš©)ê°€ ë†’ì€ í‚¤ì›Œë“œ {count}ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ì¡°ê±´:
- ê¸ˆìœµ, ë³´í—˜, ê±´ê°•, ê¸°ìˆ , ë¼ì´í”„ìŠ¤íƒ€ì¼ ë¶„ì•¼ì—ì„œ ì„ íƒ
- "êµ¬ë§¤", "ì˜ˆì•½", "ë°©ë²•", "ì¶”ì²œ", "ë¹„êµ", "ê°€ê²©", "í›„ê¸°", "ìˆœìœ„" ë“± í–‰ë™ ìœ ë„ ë‹¨ì–´ í¬í•¨
- ì‹¤ì œ êµ¬ë§¤ë‚˜ ì„œë¹„ìŠ¤ ì´ìš©ìœ¼ë¡œ ì´ì–´ì§€ëŠ” í‚¤ì›Œë“œ
- í•œêµ­ì–´ë¡œ ì‘ì„±
- ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í‚¤ì›Œë“œë§Œ ë‚˜ì—´ (ì¤„ë°”ê¿ˆ ì—†ì´)

ì˜ˆì‹œ: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, í‚¤ì›Œë“œ4, í‚¤ì›Œë“œ5
"""

    try:
        res = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=200
        )
        keywords_str = res['choices'][0]['message']['content'].strip()
        # ì¤„ë°”ê¿ˆ ì œê±°í•˜ê³  ì‰¼í‘œë¡œ ë¶„ë¦¬
        keywords_str = keywords_str.replace('\n', '').replace('-', '')
        keywords = [kw.strip() for kw in keywords_str.split(',') if kw.strip()]
        return keywords[:count]
    except Exception as e:
        print(f"âš ï¸ AI í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
        fallback_keywords = {
            "finance": ["ëŒ€ì¶œ ë¹„êµ", "ì‹ ìš©ì¹´ë“œ ì¶”ì²œ", "ë³´í—˜ ê°€ì… ë°©ë²•"],
            "health": ["ë‹¤ì´ì–´íŠ¸ ì•½ êµ¬ë§¤", "ì˜ì–‘ì œ ì¶”ì²œ", "ê±´ê°•ê²€ì§„ ì˜ˆì•½"],
            "tech": ["ë…¸íŠ¸ë¶ êµ¬ë§¤ ê°€ì´ë“œ", "ìŠ¤ë§ˆíŠ¸í° ë¹„êµ", "ê²Œì´ë° ë§ˆìš°ìŠ¤ ì¶”ì²œ"],
            "life": ["ì´ì‚¬ ì—…ì²´ ì¶”ì²œ", "ì¸í…Œë¦¬ì–´ ê²¬ì ", "ê²°í˜¼ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸"]
        }
        return fallback_keywords.get(category, ["êµ¬ë§¤ ê°€ì´ë“œ", "ì¶”ì²œ ìˆœìœ„", "ë¹„êµ ë°©ë²•"])[:count]

def get_dynamic_high_cpc_keyword():
    """ë™ì ìœ¼ë¡œ ê³ ë‹¨ê°€ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ê³  ì„ íƒí•©ë‹ˆë‹¤."""
    # ì¹´í…Œê³ ë¦¬ ì„ íƒ (ê¸°ì¡´ + AI ìƒì„±)
    categories = list(HIGH_CPC_KEYWORDS.keys()) + ["ai_generated"]
    category = random.choice(categories)
    
    if category == "ai_generated":
        # AIê°€ ì¹´í…Œê³ ë¦¬ì™€ í‚¤ì›Œë“œë¥¼ ëª¨ë‘ ìƒì„±
        keywords = generate_high_cpc_keywords(count=3)
        if keywords:
            # ì²« ë²ˆì§¸ í‚¤ì›Œë“œë§Œ ì„ íƒ (ë‹¨ì¼ ì£¼ì œ ë³´ì¥)
            selected_keyword = keywords[0]
            print(f"ğŸ¯ AI ìƒì„± í‚¤ì›Œë“œ ëª©ë¡: {keywords}")
            print(f"âœ… ì„ íƒëœ í‚¤ì›Œë“œ: {selected_keyword}")
            return selected_keyword, "ai_generated"
        else:
            # AI ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ë¡œ í´ë°±
            category = random.choice(list(HIGH_CPC_KEYWORDS.keys()))
            return random.choice(HIGH_CPC_KEYWORDS[category]), category
    else:
        # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ íƒí•˜ë˜, AIë¡œ ì¶”ê°€ í‚¤ì›Œë“œ ìƒì„±
        base_keywords = HIGH_CPC_KEYWORDS[category]
        ai_keywords = generate_high_cpc_keywords(category, count=2)
        
        # ê¸°ì¡´ í‚¤ì›Œë“œì™€ AI í‚¤ì›Œë“œë¥¼ í•©ì³ì„œ ì„ íƒ
        all_keywords = base_keywords + ai_keywords
        selected_keyword = random.choice(all_keywords)
        print(f"ğŸ¯ ì„ íƒ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ: {all_keywords}")
        print(f"âœ… ìµœì¢… ì„ íƒ: {selected_keyword}")
        return selected_keyword, category

def translate_to_english(keyword):
    """í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤."""
    try:
        prompt = f"ë‹¤ìŒ í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ì´ë¯¸ì§€ ê²€ìƒ‰ì— ì í•©í•œ ì˜ì–´ ë‹¨ì–´ë‚˜ êµ¬ë¬¸ìœ¼ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”: {keyword}"
        res = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=50
        )
        english_keyword = res['choices'][0]['message']['content'].strip()
        print(f"ğŸŒ ë²ˆì—­: '{keyword}' â†’ '{english_keyword}'")
        return english_keyword
    except Exception as e:
        print(f"âš ï¸ ë²ˆì—­ ì‹¤íŒ¨: {e}")
        return keyword

def get_pexels_image_url(keyword):
    """Pexels APIë¥¼ ì‚¬ìš©í•´ í‚¤ì›Œë“œì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ëŒ€í‘œ ì´ë¯¸ì§€ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­
    english_keyword = translate_to_english(keyword)
    
    url = f'https://api.pexels.com/v1/search?query={quote(english_keyword)}&per_page=10&page=1'
    headers = {"Authorization": PEXELS_API_KEY}
    
    print(f"ğŸ” Pexels ê²€ìƒ‰ URL: {url}")
    print(f"ğŸ”‘ API í‚¤: {PEXELS_API_KEY[:10]}...")
    
    try:
        resp = requests.get(url, headers=headers, timeout=10)
        print(f"ğŸ“¡ Pexels API ì‘ë‹µ ìƒíƒœ: {resp.status_code}")
        
        if resp.status_code != 200:
            print(f"âŒ Pexels API ì˜¤ë¥˜: {resp.text}")
            return None
            
        data = resp.json()
        photos = data.get('photos', [])
        print(f"ğŸ“¸ ì°¾ì€ ì´ë¯¸ì§€ ê°œìˆ˜: {len(photos)}")
        
        if photos:
            # ëœë¤ìœ¼ë¡œ í•œ ì¥ ì„ íƒ
            photo = random.choice(photos)
            image_url = photo['src']['large']
            print(f"âœ… ì„ íƒëœ ì´ë¯¸ì§€: {image_url}")
            return image_url
        else:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âš ï¸ Pexels ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
    return None

def run_high_cpc_strategy():
    print("\nğŸš€ [ì‹œì‘] ê³ ë‹¨ê°€ í‚¤ì›Œë“œ ê¸°ë°˜ ìë™ í¬ìŠ¤íŒ…\n")
    
    # ë™ì ìœ¼ë¡œ ê³ ë‹¨ê°€ í‚¤ì›Œë“œ ìƒì„±
    keyword, category_key = get_dynamic_high_cpc_keyword()
    print(f"ğŸ¯ ì„ íƒëœ í‚¤ì›Œë“œ: {keyword} (ì¹´í…Œê³ ë¦¬: {category_key})")

    news_url, _, news_title = get_news_url_and_og_image(keyword)
    if not news_url:
        print(f"âš ï¸ '{keyword}' ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í•´ë„ í¬ìŠ¤íŒ…ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        news_title = None
    
    # Pexelsì—ì„œ ëŒ€í‘œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
    image_url = get_pexels_image_url(keyword)
    if not image_url:
        print(f"âš ï¸ Pexelsì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    category_name = CATEGORY_MAP.get(category_key, "ì •ë³´")
    html = generate_blog_content(keyword, [news_title] if news_title else [keyword], category_name)
    post_to_wordpress(keyword, html, category_key, image_url)
    print(f"âœ… í¬ìŠ¤íŒ… ì™„ë£Œ: {keyword}")

def add_speed_optimization_meta(html, title):
    """í˜ì´ì§€ ë¡œë”© ì†ë„ ìµœì í™”ë¥¼ ìœ„í•œ ë©”íƒ€ íƒœê·¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    speed_meta = f"""
    <meta name="robots" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
    <meta name="googlebot" content="index, follow">
    <meta name="bingbot" content="index, follow">
    <link rel="canonical" href="{WP_URL.replace('/wp-json/wp/v2/posts', '')}/finance/{title.lower().replace(' ', '-')}/">
    <meta property="og:type" content="article">
    <meta property="og:title" content="{title}">
    <meta property="og:url" content="{WP_URL.replace('/wp-json/wp/v2/posts', '')}/finance/{title.lower().replace(' ', '-')}/">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="{title}">
    """
    
    # HTML ì‹œì‘ ë¶€ë¶„ì— ë©”íƒ€ íƒœê·¸ ì‚½ì…
    if '<head>' in html:
        html = html.replace('<head>', f'<head>{speed_meta}')
    else:
        html = speed_meta + html
    
    return html

if __name__ == "__main__":
    # --- ì „ëµ ì„ íƒ ---
    # 'trend': êµ¬ê¸€ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê¸°ë°˜ í¬ìŠ¤íŒ…
    # 'high_cpc': ì§€ì •ëœ ê³ ë‹¨ê°€ í‚¤ì›Œë“œ ê¸°ë°˜ í¬ìŠ¤íŒ…
    STRATEGY = "high_cpc"
    # -----------------

    if STRATEGY == "trend":
        run_trend_strategy(count=1)
    elif STRATEGY == "high_cpc":
        run_high_cpc_strategy()
    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì „ëµ: {STRATEGY}")
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
