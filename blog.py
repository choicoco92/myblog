# âœ… í†µí•©ëœ ìë™ í¬ìŠ¤íŒ… ìŠ¤í¬ë¦½íŠ¸: íŠ¸ë Œë“œ ë‰´ìŠ¤ + ì¿ íŒ¡ ìƒí’ˆ ì‚½ì… (og:image ì ìš© í¬í•¨ ì „ì²´ì½”ë“œ)


import requests, json, openai, hashlib, hmac, re, time, feedparser, random
from requests.auth import HTTPBasicAuth
from bs4 import BeautifulSoup
import requests
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from urllib.parse import quote
from urllib.parse import urlparse, unquote
from config import *

openai.api_key = OPENAI_API_KEY

CATEGORY_MAP = {
    "today-trend": "ğŸŒ ì˜¤ëŠ˜ì˜ íŠ¸ë Œë“œ",
    "ai-tech": "ğŸ¤– AI & ê¸°ìˆ ",
    "life-hacks": "ğŸ§  ìƒí™œì •ë³´",
    "today-video": "ğŸ¬ ì˜¤ëŠ˜ì˜ ì˜ìƒ",
    "briefing": "âœï¸ ì§§ì€ ë¸Œë¦¬í•‘",
    "archive": "ğŸ“š ì•„ì¹´ì´ë¸Œ"
}

COUPANG_CATEGORY_SLUG_MAP = {
    1001: "hot-now", 1002: "hot-now", 1010: "hot-now", 1011: "kids-life",
    1013: "home-living", 1014: "daily-pick", 1015: "home-living", 1016: "tech-gadgets",
    1017: "travel-leisure", 1018: "daily-pick", 1019: "daily-pick", 1020: "daily-pick",
    1021: "daily-pick", 1024: "daily-pick", 1025: "travel-leisure", 1026: "travel-leisure",
    1029: "pet-picks", 1030: "kids-life"
}

def generateHmac(method, full_url_path, secretKey, accessKey):
    from time import gmtime, strftime
    signed_date = strftime('%y%m%dT%H%M%SZ', gmtime())
    path, query = full_url_path.split('?', 1) if '?' in full_url_path else (full_url_path, "")
    message = signed_date + method + path + query
    signature = hmac.new(secretKey.encode(), message.encode(), hashlib.sha256).hexdigest()
    return f"CEA algorithm=HmacSHA256, access-key={accessKey}, signed-date={signed_date}, signature={signature}"

def get_random_best_product():
    for _ in range(5):
        category_id = random.choice(list(COUPANG_CATEGORY_SLUG_MAP.keys()))
        path = f"/v2/providers/affiliate_open_api/apis/openapi/products/bestcategories/{category_id}?limit=30"
        url = f"https://api-gateway.coupang.com{path}"
        auth_header = generateHmac("GET", path, CP_SECRET_KEY, CP_ACCESS_KEY)
        r = requests.get(url, headers={"Authorization": auth_header})
        if r.status_code == 200 and r.json().get("data"):
            p = random.choice(r.json()["data"])
            return {
                "name": p["productName"],
                "image": p["productImage"],
                "url": p["productUrl"]
            }
    return None

def get_news_title_from_url(news_url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(news_url, headers=headers, timeout=5)
        soup = BeautifulSoup(resp.text, "html.parser")
        title_tag = soup.find("meta", property="og:title")
        if title_tag:
            return title_tag["content"].strip()
        return soup.title.string.strip() if soup.title else None
    except Exception as e:
        print(f"âš ï¸ ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None


def extract_og_image(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=5)
        if resp.status_code != 200:
            return None
        soup = BeautifulSoup(resp.text, 'html.parser')
        og_tag = soup.find("meta", property="og:image")
        if og_tag and og_tag.get("content"):
            return og_tag["content"]
    except Exception as e:
        print("âš ï¸ og:image ì¶”ì¶œ ì‹¤íŒ¨:", e)
    return None

def map_keyword_to_category(keyword):
    keyword = keyword.lower()
    if any(k in keyword for k in ["ai", "chatgpt", "gpt", "suno"]):
        return "ai-tech"
    elif any(k in keyword for k in ["ë‹¤ì´ì–´íŠ¸", "ìƒí™œ", "ì •ë¦¬", "ì ˆì•½"]):
        return "life-hacks"
    elif any(k in keyword for k in ["ìœ íŠœë¸Œ", "youtube", "ì˜ìƒ", "ì‡¼ì¸ "]):
        return "today-video"
    elif any(k in keyword for k in ["ë‰´ìŠ¤", "ì†ë³´", "í—¤ë“œë¼ì¸"]):
        return "briefing"
    elif any(k in keyword for k in ["ê²°ì‚°", "ìš”ì•½", "í†µê³„", "í†±10"]):
        return "archive"
    else:
        return "today-trend"

def get_trending_with_news(count=3):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.get("https://trends.google.co.kr/trends/trendingsearches/daily?geo=KR")
    time.sleep(3)

    elements = driver.find_elements(By.XPATH, '//tr[@role="row"]/td[2]/div[1]')
    keywords = [el.text.strip() for el in elements if el.text.strip()]
    driver.quit()

    selected = keywords[:count]
    results = []

    for keyword in selected:
        print(f"ğŸ” í‚¤ì›Œë“œ: {keyword}")
        news_url, image_url, news_title = get_news_url_and_og_image(keyword)
        category = map_keyword_to_category(keyword)

        if not news_url:
            continue

        news_titles = [news_title] if news_title else [keyword]
        results.append((keyword, news_titles, category, image_url))

    return results

def get_news_url_and_og_image(keyword):
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("window-size=1920x1080")
    options.add_argument("user-agent=Mozilla/5.0")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    try:
        query = quote(keyword)
        url = f"https://search.naver.com/search.naver?query={query}"
        driver.get(url)

        wait = WebDriverWait(driver, 5)
        links = driver.find_elements(By.CSS_SELECTOR, "a[href*='n.news.naver.com']")
        news_url = None
        for link in links:
            href = link.get_attribute("href")
            if href:
                news_url = href
                break

        if not news_url:
            print(f"âŒ [{keyword}] ë‰´ìŠ¤ ë§í¬ ì—†ìŒ")
            return None, None, None

        image_url = extract_og_image(news_url)
        news_title = get_news_title_from_url(news_url)
        return news_url, image_url, news_title

    except Exception as e:
        print(f"âš ï¸ [{keyword}] ë‰´ìŠ¤ URL/ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None, None, None
    finally:
        driver.quit()

# ë¸”ë¡œê·¸ ê¸€ ìƒì„±

def generate_blog_content(keyword, news_titles, category):
    joined_titles = "\n".join([f"- {t}" for t in news_titles])
    prompt = f"""
ğŸ“° '{keyword}'ì™€ ê´€ë ¨ëœ ìµœê·¼ ë‰´ìŠ¤ ì œëª©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
{joined_titles}

ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SEOì— ìµœì í™”ëœ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

"""
    messages = [
        {
            "role": "system",
            "content": (
                "ë„ˆëŠ” SEO ìµœì í™” ë¸”ë¡œê·¸ ê¸€ì„ ì˜ ì“°ëŠ” ì‘ê°€ì…ë‹ˆë‹¤. ìš”ì²­ ì¡°ê±´ì„ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”. "
                "ì•„ë˜ ì¡°ê±´ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”: "
                "1) 800ë‹¨ì–´ ì´ìƒ, 4000ì ì´ìƒ ì‘ì„±, "
                "2) <h2>, <h3>, <h4> ë“± ë¶€ì œëª©ì—ëŠ” í¬ì»¤ìŠ¤ í‚¤ì›Œë“œë¥¼ ë„£ì§€ ì•ŠëŠ”ë‹¤ ë˜í•œ ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©, "
                "3) <h2>, <p> íƒœê·¸ í¬í•¨, "
                f"4) í¬ì»¤ìŠ¤ í‚¤ì›Œë“œ '{keyword}'ëŠ” ìµœëŒ€ 2íšŒ ì´í•˜ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš© (í‚¤ì›Œë“œ ë°€ë„ 1% ì´í•˜), ë§¤ìš°ì¤‘ìš”"
                "5) ë¶„ì„í˜• ë³¸ë¬¸ ì¤‘ì‹¬, ì¸ë¬¼ ë° ë°°ê²½ í¬í•¨, "
                "6) ê¸€ì€ ë„ì…ë¶€ / ì£¼ìš” ì´ìŠˆ ìš”ì•½ / ë°°ê²½ ì„¤ëª… / ì „ë§ / ê²°ë¡  êµ¬ì¡°ë¡œ ì‘ì„±."
            )
        },
        {"role": "user", "content": prompt}
    ]

    res = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7,
        max_tokens=3200
    )
    return res['choices'][0]['message']['content']


def extract_tags_from_text(keyword, news_titles):
    base = " ".join(news_titles) + " " + keyword
    words = re.findall(r'[ê°€-í£a-zA-Z]{2,20}', base)
    return list(set(words))[:5]


def get_or_create_category(slug):
    r = requests.get(f"{WP_URL.replace('/posts', '/categories')}?slug={slug}", auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
    if r.status_code == 200 and r.json():
        return r.json()[0]['id']
    name = CATEGORY_MAP.get(slug, slug)
    res = requests.post(
        f"{WP_URL.replace('/posts', '/categories')}",
        headers={"Content-Type": "application/json"},
        data=json.dumps({"name": name, "slug": slug}),
        auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
    )
    return res.json().get('id')


def get_or_create_tags(tag_names):
    tag_ids = []
    for tag in tag_names:
        r = requests.get(f"{WP_URL.replace('/posts', '/tags')}?search={tag}", auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD))
        if r.status_code == 200 and r.json():
            tag_ids.append(r.json()[0]['id'])
        else:
            res = requests.post(
                f"{WP_URL.replace('/posts', '/tags')}",
                headers={"Content-Type": "application/json"},
                data=json.dumps({"name": tag}),
                auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
            )
            res_json = res.json()
            tag_ids.append(res_json.get("id", res_json.get("data", {}).get("term_id")))
    return tag_ids


def reword_title(keyword):
    patterns = [
        f"{keyword} ìš”ì¦˜ ì™œ ë‚œë¦¬ì¼ê¹Œ?",
        f"{keyword} ì´ìŠˆ, ì•Œê³  ë³´ë©´ ì¶©ê²©ì ì…ë‹ˆë‹¤",
        f"{keyword} ì§€ê¸ˆ ì•ˆ ë³´ë©´ í›„íšŒí•©ë‹ˆë‹¤ ğŸ”¥",
        f"{keyword} ì™œ ê°‘ìê¸° ë–´ì„ê¹Œ?",
        f"{keyword} ìˆ¨ê²¨ì§„ ë’·ì´ì•¼ê¸° ê³µê°œ!",
        f"{keyword} ì§„ì§œ ì´ìœ ëŠ” ë”°ë¡œ ìˆë‹¤",
        f"{keyword} ë‰´ìŠ¤ ë³´ë‹¤ê°€ ì†Œë¦„ ë‹ì€ ì´ìœ "
    ]
    return random.choice(patterns)


def generate_meta_description(title):
    patterns = [
        f"{title} ì— ëŒ€í•´ ì§€ê¸ˆ ê°€ì¥ ê¶ê¸ˆí•œ í•µì‹¬ ë‚´ìš©ì„ 1ë¶„ ë§Œì— ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤. ìµœì‹  íŠ¸ë Œë“œ, ì´ìŠˆ, ê·¸ë¦¬ê³  ì•Œì•„ë‘ë©´ ëˆ ë˜ëŠ” ì •ë³´ê¹Œì§€ ì´ì •ë¦¬!",
        f"{title} ê´€ë ¨ ë‰´ìŠ¤ì™€ ì´ìŠˆë“¤ì„ í•œëˆˆì— ë³´ê¸° ì‰½ê²Œ ì •ë¦¬í–ˆì–´ìš”. ì§€ê¸ˆ ì•Œì•„ë‘ë©´ ë¶„ëª…íˆ ìœ ìš©í•  ì •ë³´ë§Œ ì½• ì§‘ì–´ì„œ ì „í•´ë“œë¦½ë‹ˆë‹¤!",
        f"{title} ì´ìŠˆê°€ ì™œ ë– ì˜¤ë¥´ê³  ìˆëŠ”ì§€, ì§€ê¸ˆ ë¬´ì—‡ì„ ì¤€ë¹„í•´ì•¼ í•˜ëŠ”ì§€ê¹Œì§€ ì•Œ ìˆ˜ ìˆëŠ” í•µì‹¬ ìš”ì•½ ê°€ì´ë“œì…ë‹ˆë‹¤. ì ˆëŒ€ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”!",
        f"{title} ì— ëŒ€í•´ ì§€ê¸ˆ ê¼­ ì•Œì•„ì•¼ í•  ë°°ê²½ê³¼ ì´ìŠˆë¥¼ ì‰½ê²Œ í’€ì–´ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. í•µì‹¬ í¬ì¸íŠ¸ë¥¼ 3ë¶„ ì•ˆì— í™•ì¸í•˜ì„¸ìš”! ìµœê·¼ ë§ì€ ì‚¬ëŒë“¤ì´ ê´€ì‹¬ì„ ê°–ê³  ìˆëŠ”ì¤‘ " ,
        f"{title} ì— ëŒ€í•œ ìµœì‹  ì •ë³´ì™€ íŠ¸ë Œë“œë¥¼ ë¹ ë¥´ê²Œ ìš”ì•½í•œ ì½˜í…ì¸ ì…ë‹ˆë‹¤. ì‹¤ìƒí™œì— ë„ì›€ì´ ë˜ëŠ” í•µì‹¬ ì •ë³´ë§Œ ì—„ì„ í•´ì„œ ë‹´ì•˜ì–´ìš”!"
    ]
    return random.choice(patterns)


def upload_image_to_wp(image_url):
    try:
        resp = requests.get(image_url, timeout=10)
        resp.raise_for_status()
        img_data = resp.content
    except Exception as e:
        print("âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨:", e)
        return None

    # ğŸ”§ ì¿¼ë¦¬ ìŠ¤íŠ¸ë§ ì œê±° + ì•ˆì „í•œ í™•ì¥ì ì¶”ì¶œ
    parsed_url = urlparse(image_url)
    clean_path = parsed_url.path  # /image/abc.jpg
    filename = clean_path.split("/")[-1]
    filename = unquote(filename)
    ext = filename.split(".")[-1].lower().split("?")[0]

    content_type = {
        "jpg": "image/jpeg",
        "jpeg": "image/jpeg",
        "png": "image/png",
        "webp": "image/webp"
    }.get(ext, "image/jpeg")

    media_headers = {
        "Content-Disposition": f"attachment; filename={filename}",
        "Content-Type": content_type
    }

    try:
        media_response = requests.post(
            WP_URL.replace("/posts", "/media"),
            headers=media_headers,
            data=img_data,
            auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
        )
        media_response.raise_for_status()
        media_json = media_response.json()
        print("âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ:", media_json.get("source_url"))
        return media_json["id"]
    except Exception as e:
        print("âŒ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨:", e)
        return None

def generate_tags_with_gpt(keyword, news_titles):
    prompt = f"""
ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¸”ë¡œê·¸ìš© íƒœê·¸ í›„ë³´ë¥¼ 10ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”. 

ì¤‘ì‹¬ í‚¤ì›Œë“œ: {keyword}
ê´€ë ¨ ë‰´ìŠ¤ ì œëª©: {" / ".join(news_titles)}

ì¡°ê±´:
- ê° íƒœê·¸ëŠ” 1~4ë‹¨ì–´ ì‚¬ì´
- ì¤‘ë³µ ì—†ì´ 10ê°œ
- ê´€ë ¨ ì¸ë¬¼, ê¸°ì—…, ì§€ì—­, ìƒí™© í¬í•¨ ê°€ëŠ¥
- ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥

ì˜ˆì‹œ ì¶œë ¥: í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3 ...
"""
    res = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5
    )
    tags_str = res['choices'][0]['message']['content']
    return [tag.strip() for tag in tags_str.split(",") if tag.strip()]

def post_to_wordpress(title, html, category_slug, image_url):
    cat_id = get_or_create_category(category_slug)
    meta_desc = generate_meta_description(title)
    slug = re.sub(r'\s+', '-', title.lower())
    try:
        tag_names = generate_tags_with_gpt(title, [title])
    except Exception as e:
        print("âš ï¸ GPT íƒœê·¸ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´:", e)
        tag_names = extract_tags_from_text(title, [title])

    tag_ids = get_or_create_tags(tag_names)

    media_id = None
    if image_url:
        media_id = upload_image_to_wp(image_url)
        html = f'<img src="{image_url}" alt="{title}" style="max-width:100%; border-radius:10px;" />\n<br> <br>' + html

    product = get_random_best_product()
    if product:
        html += f"""
    <h3>ğŸ›ï¸ ì˜¤ëŠ˜ì˜ ì¶”ì²œ ì•„ì´í…œ</h3>
    <p><strong>ì´ í¬ìŠ¤íŒ…ì€ ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ í™œë™ì˜ ì¼í™˜ìœ¼ë¡œ, ì´ì— ë”°ë¥¸ ì¼ì •ì•¡ì˜ ìˆ˜ìˆ˜ë£Œë¥¼ ì œê³µë°›ìŠµë‹ˆë‹¤.</strong></p>
    <p><strong>{product['name']}</strong> ì œí’ˆì´ì—ìš”!</p>
    <img src="{product['image']}" style="max-width:100%; border-radius:10px;">
    <br>
    <a href="{product['url']}" target="_blank" style="display:inline-block; margin-top:10px; background:#ff4800; color:white; padding:10px 20px; border-radius:5px;">ğŸ›’ ìƒì„¸ ë³´ê¸°</a>
    """

    # âœ… ë‚´ë¶€ ë§í¬ ìë™ ì‚½ì…
    html += f'''
    <h3>ğŸ“Œ ê´€ë ¨ ì½˜í…ì¸  ë” ë³´ê¸°</h3>
    <ul>
      <li><a href="/category/{category_slug}">ğŸŒ ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ëª¨ì•„ë³´ê¸°</a></li>
    </ul>
    '''

    post = {
        "title": reword_title(title),
        "slug": slug,
        "content": html,
        "status": "publish",
        "categories": [cat_id],
        "tags": tag_ids,
        "meta": {
            "rank_math_focus_keyword": title,
            "rank_math_title": title,
            "rank_math_description": meta_desc
        }
    }

    r = requests.post(
        WP_URL,
        headers={"Content-Type": "application/json"},
        data=json.dumps(post),
        auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
    )

    if r.status_code in [200, 201]:
        post_id = r.json().get("id")
        print("âœ… ê¸€ ë“±ë¡ ì™„ë£Œ:", r.json().get('link'))

        if media_id:
            patch_res = requests.put(
                f"{WP_URL}/{post_id}",
                headers={"Content-Type": "application/json"},
                data=json.dumps({"featured_media": media_id}),
                auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
            )
            print("ğŸ–¼ ëŒ€í‘œ ì´ë¯¸ì§€ ì €ì¥ ì‘ë‹µ:", patch_res.status_code)

            refresh_res = requests.put(
                f"{WP_URL}/{post_id}",
                headers={"Content-Type": "application/json"},
                data=json.dumps({"status": "publish"}),
                auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
            )
            print("ğŸ”„ ì¬ì €ì¥ ì™„ë£Œ:", refresh_res.status_code)

        trigger_seo_recalc(post_id)

    else:
        print("âŒ ë“±ë¡ ì‹¤íŒ¨:", r.text)

def trigger_seo_recalc(post_id):
    try:
        refresh_res = requests.put(
            f"{WP_URL}/{post_id}",
            headers={"Content-Type": "application/json"},
            data=json.dumps({"status": "publish"}),
            auth=HTTPBasicAuth(WP_USERNAME, WP_PASSWORD)
        )
        if refresh_res.status_code == 200:
            print("âœ… Rank Math SEO ì ìˆ˜ ì¬ê³„ì‚° íŠ¸ë¦¬ê±° ì™„ë£Œ")
        else:
            print("âš ï¸ Rank Math ì ìˆ˜ íŠ¸ë¦¬ê±° ì‹¤íŒ¨:", refresh_res.status_code, refresh_res.text)
    except Exception as e:
        print("âŒ Rank Math íŠ¸ë¦¬ê±° ì¤‘ ì˜¤ë¥˜:", e)

if __name__ == "__main__":
    print("\nğŸš€ [ì‹œì‘] íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê¸°ë°˜ ìë™ í¬ìŠ¤íŒ… ì‹¤í–‰\n")
    items = get_trending_with_news(count=1)  # ì˜ˆ: í‚¤ì›Œë“œ 5ê°œ ê°€ì ¸ì˜´

    for idx, (keyword, news, category, image_url) in enumerate(items, 1):
        print(f"\nğŸŒ€ [{idx}] í‚¤ì›Œë“œ ì²˜ë¦¬ ì‹œì‘: {keyword}")

        if not news:
            print("âš ï¸ ë‰´ìŠ¤ ì—†ìŒ, ê±´ë„ˆëœ€")
            continue
        print(f"ğŸ“ GPT ë³¸ë¬¸ ìƒì„± ì¤‘... ({keyword})")
        html = generate_blog_content(keyword, news, CATEGORY_MAP[category])
        print(f"ğŸ“¤ ì›Œë“œí”„ë ˆìŠ¤ í¬ìŠ¤íŒ… ì‹œì‘... ({keyword})")
        post_to_wordpress(keyword, html, category, image_url)
        print(f"âœ… [{idx}] í‚¤ì›Œë“œ ì™„ë£Œ: {keyword} â†’ ë‹¤ìŒìœ¼ë¡œ ì´ë™\n")
        time.sleep(2)  # â† ì—¬ê¸°ì„œ 1ê°œ ë°œí–‰ ëë‚˜ê³  ë‹¤ìŒ í‚¤ì›Œë“œ ì§„í–‰
    print("\nğŸ‰ ì „ì²´ í¬ìŠ¤íŒ… ì™„ë£Œ!")
